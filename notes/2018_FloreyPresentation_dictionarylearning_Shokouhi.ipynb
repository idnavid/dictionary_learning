{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sparse Dictionary Learning for Data Driven Analysis of Neuroimaging Signals\n",
    "Presenter: Navid Shokouhi\n",
    "\n",
    "*The University of Melbourne*\n",
    "\n",
    "work in collaboration with Dr. Abd-Krim Seghouane\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "- Presenter Background\n",
    "    - Previous Work\n",
    "- Data-driven functional analysis for resting-state fMRI\n",
    "    - ICA\n",
    "- Sparse Dictionary Learning\n",
    "- Numerical Results\n",
    "- Directions of Future Work \n",
    "- Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Navid Shokouhi\n",
    "PhD in *Statistical Signal Processing* and *Machine Learning*\n",
    "- *The University of Texas at Dallas, USA*\n",
    "- Worked on machine learning for speech applications: spoken dialogue systems\n",
    "\n",
    "\n",
    "Postdoc in *Statistical Signal Processing* and *Machine Learning*\n",
    "- *The University of Melbourne*\n",
    "- functional data analysis for Neuroimaging\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Research Interests:\n",
    "    - Statistical interpretation of Machine Learning Algorithms\n",
    "    - Multivariate statistical analysis: PCA, ICA, CCA, LDA\n",
    "    - Sparse Statistical Learning \n",
    "    \n",
    "    \n",
    "- Research Experience:\n",
    "    - Machine learning for data driven Neuroimaging analysis: \n",
    "        - fMRI, fNIRS\n",
    "    - Speech Recognition and Voice biometrics\n",
    "        - PhD dissertation\n",
    "\n",
    "\n",
    "- Professional (non-academic) Experience:\n",
    "    - *Pull String Inc., San Francisco, CA, USA*\n",
    "        - Software developer in applied Computational Linguistics\n",
    "        - Python/C++\n",
    "    - Work in collaboration with *Samsung, USA*\n",
    "        - Speech Recognition for Smart TVs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Previous Work in Neuroimaging:\n",
    "- Model order selection for ICA (resting-state fMRI analysis)\n",
    "    <img src=\"figures/2018_TMI_RSNplotOrderselection_SeghouaneShokouhi.png\" alt=\"RSN_orderselection\" height=\"100\"/>\n",
    "\n",
    "**Seghouane, Shokouhi, \"Consistent Estimation of Dimensionality for Data-Driven Methods in fMRI Analysis\", Transactions on Medical Imaging, 2018.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Model order selection for CCA (multi-modal data analysis)\n",
    "<img src=\"figures/2018_TSP_CCAorderselection_SeghouaneShokouhi.png\" alt=\"RSN_orderselection\" height=\"75\"/>\n",
    "\n",
    "**Seghouane, Shokouhi, \"Estimating the number of Significant Canonical Coordinates\", Transactions on Signal Processing, (submitted) 2018.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Robust Estimation of the Haemodynamic Response Function\n",
    "    <img src=\"figures/2018_unpublished_HRFestimation_SeghouaneShokouhi.png\" alt=\"HRF_alpharobust\" width=\"200\"/>\n",
    "    <img src=\"figures/2018_unpublished_HRFestimationAlphaRobustPairs_SeghouaneShokouhi.png\" alt=\"HRF_alpharobust\" width=\"400\"/>\n",
    "\n",
    "**Seghouane, Shokouhi, \"Robust Estimation of Output Layer Parameters for RBFNs\", Transactions on Cybernetics, (submitted) 2018.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Sparse PCA as a preprocessing step for ICA\n",
    "    <img src=\"figures/2018_TIP_SparsePCArealfmri_SeghouaneShokouhiKoch.png\" alt=\"sparsePCA\" width=\"200\"/>\n",
    "\n",
    "**Seghouane, Shokouhi, Koch, \"Sparse Principal Component Analysis with Preserved Sparsity Pattern\", Transactions on Image Processing, (submitted) 2018.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Simultaneous spatio-temporal data normalization (2D whitening)\n",
    "<img src=\"figures/2018_SPL_twodimensional_SeghouaneShokouhi.png\" alt=\"twoD\" width=\"400\"/>\n",
    "\n",
    "**Seghouane, Shokouhi, \"Two-Dimensional Whitening of Face Images for Improved PCA Performance\n",
    ", Signal Processing Letters, 2018.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data-driven functional analysis for resting-state fMRI\n",
    "Popular fMRI data analysis tools:\n",
    "- General Linear Model\n",
    "    - variant of the linear regression fitted by least-squares to each voxel (aka SPM).\n",
    "    - useful for studying brain response to task stimuli\n",
    "- Data-driven methods\n",
    "    - principal/independent component analysis\n",
    "    - can be used for both task-dependent and resting-state data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Task-dependent\n",
    "<img src=\"figures/taskdependent_fMRI.png\" alt=\"sparsePCA\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Resting-state \n",
    "Without Paradigm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our data is the collection of voxel time-series. \n",
    "    <img src=\"figures/boldsignal_fmri.png\" alt=\"bold\" width=\"400\"/>\n",
    "\n",
    "**Resting-state networks**: spontaneous (i.e., non task-dependent) BOLD signals that are known to be functionally and/or structurally related. \n",
    "\n",
    "An example is the **default mode network (DMN)**, which shows a decrease in activity during cognitive tasks, inversely related to regions activated by cognitive tasks. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Formulation used in Data-Driven Methods\n",
    "Let ${\\bf Y} = [{\\bf y}_1,\\dots,{\\bf y}_m]$ represents the data matrix comprised of vector samples of a BOLD signal at voxel $i$,\n",
    "\n",
    "where ${\\bf y}_i\\in R^m$ for $i=1,\\dots,N$.\n",
    "\n",
    "For each voxel $i$ assume the linear mixture model: \n",
    "$${\\bf y}_i = {\\bf D}{\\bf x}_i + \\boldsymbol{\\epsilon}_i$$\n",
    "where $\\boldsymbol{\\epsilon}_i$ correspond to noise. \n",
    "\n",
    "In matrix format (concatenating all ${\\bf y}_i$, ${\\bf x}_i$, and $\\boldsymbol{\\epsilon}_i$):\n",
    "$${\\bf Y} = {\\bf D}{\\bf X} + {\\bf E}$$\n",
    "\n",
    "\n",
    "> **The main objective of any data-driven method is to perform the matrix decomposition** \n",
    "${\\bf Y} \\approx {\\bf D}{\\bf X}$ \n",
    "**, which is done using certain assumptions on ** \n",
    "${\\bf D}$ \n",
    "**and/or** \n",
    "${\\bf X}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Independent Component Analysis (ICA)\n",
    "ICA has become the most popular data-driven method for fMRI analysis. \n",
    "\n",
    "It finds an unmixing matrix ${\\bf W}$, such that:\n",
    "$$\\hat{\\bf x}_i = {\\bf W}{\\bf y}_i$$ \n",
    "or similarly\n",
    "$$\\hat{\\bf X} = {\\bf W}{\\bf Y}$$ \n",
    "\n",
    "ICA enforces an independence assumption on the vectors constructing ${\\bf X}$ to perform decomposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Spatial ICA\n",
    "There are two ways to address ICA:\n",
    "\n",
    "1) spatial ICA (sICA): extracts spatially independent brain maps\n",
    "<img src=\"figures/spatial_ICA.png\" alt=\"sICA\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1) temporal ICA (sICA): extracts temporally independent time series'\n",
    "<img src=\"figures/temporal_ICA.png\" alt=\"sICA\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Short-comings of ICA\n",
    "- Some studies have questioned the independence assumption in brain activity analysis for fMRI data.\n",
    "    - interconnections of neural networks.\n",
    "    - preprocessing steps such as smoothing, normalization affect independence. \n",
    "    \n",
    "> **We would like to use a more effective data-driven method that overcomes the aforementioned short-comings of ICA in fMRI data analysis.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sparsity vs. Independence\n",
    "ICA algorithms are known to work well if the components (i.e., elements of ${\\bf X}$) have *generalized Gaussian densities*. \n",
    "$$p(x) = C e^{-\\alpha |x|^\\gamma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, a special case is when $\\gamma=1$, forming a Laplacian prior on ${\\bf X}$. \n",
    "\n",
    "This prior is commonly known as a sparsity assumption on ${\\bf X}$, meaning that most of its elements are $0$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sparse Dictionary Learning\n",
    "Using the same model as before:\n",
    "$${\\bf y}_i = {\\bf D}{\\bf x}_i + \\boldsymbol{\\epsilon}_i$$\n",
    "\n",
    "- ${\\bf D}$ is called a dictionary of size $m\\times k$. \n",
    "- $k \\gg m$, meaining that ${\\bf D}$ contains redundancy. \n",
    "- ${\\bf x}_i$ is a sparse set of coefficients for the columns of ${\\bf D}$. \n",
    "\n",
    "In matrix format, sparse dictionary learning solves:\n",
    "$$ min_{\\bf D,X} \\parallel {\\bf Y} - {\\bf DX}\\parallel_{F}^2 $$\n",
    "$$s.t.: \\parallel {\\bf x}_i\\parallel_{0} < \\alpha$$\n",
    "\n",
    "- $\\parallel \\parallel_0$ is the number of non-zero elements in a vector. \n",
    "\n",
    "In sparse dictionary learning for fMRI:\n",
    "> **Each BOLD signal**\n",
    "${\\bf y}_i$ \n",
    "**is represented as a sparse linear combination of the dictionary elements.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/dictionary_learning_decomposition.png\" alt=\"dict_learning\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Typically, an approximation is solved: \n",
    "$$ min_{\\bf D,X} \\parallel {\\bf Y} - {\\bf DX}\\parallel_{F}^2 $$\n",
    "$$s.t.: \\parallel {\\bf x}_i\\parallel_{1} < \\beta$$\n",
    "\n",
    "Using $\\parallel \\parallel_1$ instead of $\\parallel \\parallel_0$: \n",
    "- while inducing sparsity\n",
    "- is solvable\n",
    "- is related to Bayesian estimation through the Laplace prior $p(x) = C e^{-\\alpha |x|}$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Introducing prior information\n",
    "One of the benefits of sparse dictionary learning is that it allows introducing prior information on the **spatial and/or temporal structure** of the data. \n",
    "\n",
    "For example:\n",
    "$$ min_{\\bf D,X} \\parallel {\\bf Y} - {\\bf DX}\\parallel_{F}^2 + \\lambda\\parallel {\\bf D}\\parallel_{F}^2$$\n",
    "$$s.t.: \\parallel {\\bf x}_i\\parallel_{1} < \\beta$$\n",
    "\n",
    "gives smooth dictionary components [1]. \n",
    "\n",
    "**[1] M. Yaghoobi, T. Blumensath and M. Davies, “Regularized dictionary learning for sparse approximation”, EUSIPCO 2008.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical Results\n",
    "<img src=\"figures/simulation_1.png\" alt=\"sICA\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/simulation_2.png\" alt=\"sICA\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary of advantages of sparse dictionary learning\n",
    "- Sparse dictionary learning (DL) can be connected to ICA. \n",
    "- Sparse DL imposes less restrictive assumptions on the data.\n",
    "- Sparse DL is easier to extend to introduce spatio-temporal structure. \n",
    "- The optimization solved in sparse DL is scalable (allows both batch and online processing).\n",
    "- Sparse DL results are reproducable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Directions for future work\n",
    "- Extensive multi-subject studies for resting-state fMRI analysis using sparse DL. \n",
    "    - Most work on sparse dictionary learning in fMRI is scarce and performed on limited data. \n",
    "- Improving the robustness of sparse dictionary learning. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
